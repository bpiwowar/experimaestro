#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK

import os
import os.path
import sys
import subprocess
import argparse
import string
import logging
import re
from icolor import cformat
import traceback
import base64
import websocket
import json
import argcomplete
import socket
import requests
import signal
import errno
import click
from functools import update_wrapper

# --- Set some variables

logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

xpmdir = os.path.dirname(os.path.realpath(os.path.abspath(__file__)))
xpminidir = os.path.join(os.path.expanduser("~/.experimaestro"))

version = "0.0.1-SNAPSHOT"
jarname = "experimaestro-%s.jar" % version
STATES = ["DONE", "ERROR", "ON_HOLD", "RUNNING", "READY", "WAITING"]

def pass_cfg(f):
    """Pass configuration information"""
    @click.pass_context
    def new_func(ctx, *args, **kwargs):
        return ctx.invoke(f, ctx.obj, *args, **kwargs)
    return update_wrapper(new_func, f)



## --- TO REMOVE

parser = argparse.ArgumentParser(description='experimaestro script.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
subparsers = parser.add_subparsers(help='Command', dest='command')

p_xp = subparsers.add_parser("experiments", help="Manage experiments", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
xp_subparsers = p_xp.add_subparsers(help='Command', dest='subcommand')

parser.set_defaults(dir=xpmdir)
parser.add_argument("--log", dest="loglevel", action="store", help="Log level",
                    choices=("debug", "info", "warn"), default="info")

parser.add_argument("--debug", dest="debug", action="store_true", help="Debug script")
parser.add_argument("--verbose", dest="verbose", action="store_true", help="Use verbose mode for XML-RPC server")
parser.add_argument("--config", dest="config", default="~/.experimaestro/settings.json", action="store",
                    help="Experimaestro configuration file")
parser.add_argument("--server", dest="server", action="store", help="The experimaestro server to use")

subparser = subparsers.add_parser("stop-server", help="Stop the experimaestro server")

job_specification = argparse.ArgumentParser(add_help=False)
job_specification.add_argument('--states', dest="states", help="States")
job_specification.add_argument('resources', nargs='*', help="The resources", default=[])
job_specification.add_argument('--recursive', dest="recursive", action="store_true", default=False, help="Should dependent resources be included?")

subparsers.add_parser("update", help="Update jobs", parents=[job_specification])

subparsers.add_parser("list-methods", help="List Json RPC methods")
subparsers.add_parser("ssh-agent", help="List Json RPC methods")

p_invalidate = subparsers.add_parser("invalidate", help="Invalidate a job")
p_experiments_invalidate = xp_subparsers.add_parser("invalidate", help="Invalidate jobs for an experiment")

for subp in [p_invalidate, p_experiments_invalidate]:
    subp.add_argument('--no-recursion', dest="recursive", action="store_false", default=True, help="Should dependent resources be restarted?")
    subp.add_argument('--restart', dest="restart", action="store_true", default=False, help="Restart instead of setting to ERROR")
    subp.add_argument('--invalidate-done', action="store_false", default=True, dest="keep_done", help='The experiment ID')

p_experiments_invalidate.add_argument('--states', dest="states", default="ERROR,RUNNING", help="States to invalidate")
p_experiments_invalidate.add_argument('experimentId', help='The experiment ID')

p_invalidate.add_argument('resourceIds', nargs="+", help='The resource URI')

p_information = subparsers.add_parser("information", help="Get information on a resource")
p_information.add_argument('resourceId', nargs=1, help='The resource URI')

p_lock_cleanup = subparsers.add_parser("lock-cleanup", help="Cleanup dandling locks")
p_lock_cleanup.add_argument("--run", default=False, action="store_true", help="Really do it")

p_rm = subparsers.add_parser("rm", help="Remove a resource")
p_rm.add_argument('--regexp', dest="regexp", action="store_true", default=False, help="If the provided id are regular expressions")
p_rm.add_argument('--states', dest="states", help="States")
p_rm.add_argument('--group', dest="group")
p_rm.add_argument('--recursive', dest="recursive", action="store_true", default=False, help="Should dependent resources be removed?")
p_rm.add_argument('jobid', nargs="*", help="The job ids")

p_kill = subparsers.add_parser("kill", help="Kill a job")
p_kill.add_argument('jobid', nargs="+", help="The job URIs or IDs")

# --- Experiments


p_xp_kill = xp_subparsers.add_parser("kill", help="Kill jobs from an experiment")
p_xp_kill.add_argument('--states', dest="states", default="WAITING,READY,RUNNING", help="States")
p_xp_kill.add_argument('experimentid', help="The experiment ID")

p_xp_delete = xp_subparsers.add_parser("delete", help="Delete an experiment")
p_xp_delete.add_argument('experimentid', help="The experiment ID")


# --- Other

p_generate_files = subparsers.add_parser("generate-files", help="Generate files")
p_generate_files.add_argument('jobid', nargs="+", help="The job URIs or IDs")


p_log_level = subparsers.add_parser("log-level", help="Set the logger level")
p_log_level.add_argument('id', nargs=1, help='The logger ID')
p_log_level.add_argument('level', nargs=1, choices=["TRACE", "DEBUG", "INFO", "WARN", "ERROR", "FATAL"], help='The level')


p_tokenlimit = subparsers.add_parser("set-token-limit", help="Set the token limit")
p_tokenlimit.add_argument('tokenid', help="The token resource ID (internal or external)")
p_tokenlimit.add_argument('limit', help="The new limit")

subparsers.add_parser("build-information", help="Returns experimaestro build information")

p_move_resources = subparsers.add_parser("move-resources", help="Change path prefix")
p_move_resources.add_argument("old", type=str)
p_move_resources.add_argument("new", type=str)


# --- Utiliy classes and methods

def mkdir_p(path):
    """Similar to ``mkdir -p path``.
    """
    if not path:
        return
    try:
        os.makedirs(path)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise e

class JsonRPCMethod:
    def __init__(self, client, name):
        self.client = client
        self.name = name

    def __getattr__(self, name):
        return JsonRPCMethod(self.client, "%s.%s" % (self.name, name))

    def __getitem__(self, name):
        return self.__getattr__(name)

    def __call__(self, args):
        return self.client.call(self.name, args)

XPM_LOG_LEVELS = {
    "ERROR": logging.ERROR,
    "INFO": logging.INFO,
    "DEBUG": logging.DEBUG,
    "CRITICAL": logging.CRITICAL,
    "WARN": logging.WARN
}

class JsonRPCClient:
    def __init__(self, websocketclient):
        self.websocketclient = websocketclient
        self.jsonid = 0

    def __getattr__(self, name):
        return JsonRPCMethod(self, name)

    def __getitem__(self, name):
        return self.__getattr__(name)

    def call(self, command, params):
        logging.info("[Executing command] %s", command)
        self.jsonid += 1
        msg = json.dumps({"id": self.jsonid, "method": command, "params": params})
        self.websocketclient.send(msg)

        while self.websocketclient is not None:
            message = self.websocketclient.recv()
            o = json.loads(message)
            if type(o) == dict:
                if "id" in o:
                    if o.get("error", 0) != 0:
                        raise RuntimeError("Error while calling method %s: [%d] %s" %
                                           (self.name, o["error"]["code"], o["error"]["message"]))
                    return o["result"]
                else:
                    result = o["result"]
                    logging.info("Response: %s", result)
                    if result.get("type", "") == "log":
                        logging.log(logging.WARN, result["message"])
                    elif result["stream"] == "out":
                        sys.stdout.write(result["value"])
                    else:
                        sys.stdout.write(result["value"])



# --- Check paths

def binpaths():
    """Returns the different paths where the JAR file can be located"""
    yield os.path.join(xpmdir, "bin", "experimaestro-server")


def start_jar(args, jarargs):
    import daemonlib
    import time

    conf = Configuration(args)
    os.environ["EXPERIMAESTRO_CONFIG_FILE"] = conf.configfile

    workdir = conf.config.sub("server")["database"]
    mkdir_p(workdir)

    # Check what if we start using gradle
    gradlewFile = os.path.join(os.path.dirname(xpmdir), "gradlew.bat" if os.name == "nt" else "gradlew")
    if not os.path.exists(gradlewFile):
        gradlewFile = None

    if args.gradle or gradlewFile is not None:
        logging.info("Starting with gradle")
        command = [gradlewFile, "--project-dir", os.path.dirname(gradlewFile), "server"]

    else:
        binpath = None
        for f in binpaths():
            print("Trying %s" % f)
            if os.path.isfile(f):
                binpath = f
                break

        if binpath is None:
            raise RuntimeError("Could not find experimaestro bin directory")
        command = [binpath, "server"]

    def start_server(logger):
        logger.info("Starting experimaestro server...")
        logger.debug("start command: {!r}".format(command))
        with open(os.path.join(workdir, "server.out"), "w") as stdout, \
             open(os.path.join(workdir, "server.err"), "w") as stderr:
            return subprocess.call(command,
                                   stdout=stdout,
                                   stderr=stderr,
                                   # FIXME(Nicolas Despres): Same remarks
                                   #  than for daemonlib.daemonize().
                                   close_fds=True)

    def wait_server(pid):
        logging.info("Waiting for server to start (PID=%s)...", pid)
        logging.debug("this is a debug message")
        json_server = conf.getServer()
        logging.debug("info after getting json server")
        TIMEOUT = args.timeout # sec
        if TIMEOUT <= 0:
            raise ValueError("invalid timeout value: {}".format(TIMEOUT))
        started_at = time.time()
        nattempt = 0
        last_error = None
        while True:
            try:
                nattempt += 1
                logging.debug("%d attempt to ping server...", nattempt)
                rc = raw_ping(json_server)
            except requests.exceptions.ConnectionError as e:
                logging.debug("Ping failed: %s" % type(e.args[0]))
                # if e.args[0].args[1].errno != errno.ECONNREFUSED:
                #     logging.error("Ping failed: %s", e)
                last_error = e
            else:
                if rc:
                    logging.info("Server started...")
                    break
            if time.time() - started_at >= TIMEOUT: # sec
                logging.fatal("Timeout after %ds pinging the server",
                              TIMEOUT)
                if last_error is not None:
                    logging.fatal("Last error was: %s", last_error)
                logging.debug("Send SIGTERM to process group %d", pid)
                os.kill(-pid, signal.SIGTERM)
                break
            time.sleep(1)
        return 0

    daemonlib.daemonize(start_server, wait_server,
        daemon_cwd=workdir,
        pid_file=os.path.join(workdir, "server.pid"),
        log_level=logging.DEBUG if args.debug else logging.INFO,
        # FIXME(Nicolas Despres): Turn close_fds to True:
        #   In theory a gentle daemon closed all its opened fds before to start
        #   (i.e. the copy of fds inherited from its parent). However, in
        #   our case this leads to un-deterministic error such as the client
        #   (i.e. run-js) complaining about the socket being already closed.
        #   We can see in the daemon log that the daemon processs
        #   (i.e. our child) closes some fds which are probably some socket
        #   opened by the JsonServer or the like. It would require further
        #   debugging to diagnostic that. In theory, closing in a child
        #   process a socket created in the parent is not a problem, but in
        #   our case things seems to work better when we do not close them.
        close_fds=True)

class Properties:
    def __init__(self, map=[None, {}]):
        self.map = map

    def __len__(self):
        return len(self.map[1])

    def __getitem__(self, name):
        v = self.sub(name, None)
        if v is None:
            raise KeyError("No key '%s' in properties" % name)
        return v.map[0]

    def keys(self):
        return self.map[1].keys()

    def get(self, name, default=None):
        v = self.sub(name, None)
        if v is None:
            return None
        return v.map[0]

    def __str__(self):
        return "Properties (%s)" % self.map.__str__()

    def __iter__(self):
        for k, v in self.map[1].items():
            yield k, Properties(v)

    def sub(self, name, default=None):
        c = self.map
        for k in name.split("."):
            if not k in c[1]:
                return default
            else:
                c = c[1][k]
        return Properties(c)

    def set(self, name, value):
        c = self.map
        for k in name.split("."):
            if not k in c[1]:
                c[1][k] = [None, {}]
            c = c[1][k]

        c[0] = value


class Configuration():
    def __init__(self, config, server):
        """Get the configuration from command line and configuration file"""

        # Get the configuration
        self.configfile = os.path.expanduser(config)

        # Initialise the server
        with open(self.configfile, "r") as fp:
            self.config = json.load(fp)

        clients = self.config.get("hosts", None)
        if clients is None:
            raise RuntimeError("No hosts in configuration file")

        if server is None:
            if len(clients) > 1:
                server = None
                for name, client in clients:
                    if client.get("default", False) == "true":
                        if server is None:
                            server = name
                            logging.debug("Default server is %s" % name)
                        else:
                            raise RuntimeError("More than one client defined as default in configuration file")
                if server is None:
                    raise RuntimeError("More than one client [%d] in configuration file (%s): use the --server option or make one client the default"
                                    % (len(clients), ",".join(clients.keys())))
            else:
                for name, client in clients.items():
                    server = name

        self.client = clients[server]
        self.remote = self.client.get("remote", False) in ["true", "True", "1"]


    def getServer(self):
        scheme = "ws"
        url = "%s://%s:%d/web-socket" % (scheme, self.client.get("host", "localhost"), self.client.get("port", 8080))
        header = []
        auth = base64.b64encode(bytes("%s:%s" % (self.client["username"], self.client["password"]), "ascii")).decode("ascii")
        header = ["Authorization: Basic %s" % auth]


        return JsonRPCClient(websocket.create_connection(url, header=header))


# --- Main

@click.group()
@click.pass_context
@click.option('--debug', is_flag=True, help="Debug script")
@click.option('--verbose', is_flag=True, help="Debug script")
@click.option("--log", help="Log level",
                    type=click.Choice(["debug", "info", "warn"]), default="info")
@click.option('--server', help="The experimaestro server to use")
@click.option('--config', help="Sets experimaestro file", default="~/.experimaestro/settings.json")
def main(ctx, debug, verbose, log, server, config):
    numeric_level = getattr(logging, log.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError('Invalid log level: %s' % log)
    logging.basicConfig(level=logging.DEBUG if debug else logging.INFO)
    ctx.obj = Configuration(config, server)



# --- Server

def raw_ping(json_server):
    return json_server.ping({}) == "pong"

def ping(json_server):
    try:
        return raw_ping(json_server)
    except socket.error as e:
        return False


@main.group(help="Manage server")
def server():
    pass

@server.command(help="Start the experimaestro server")
@click.option("--gradle", is_flag=True, help="Force starts using gradle")
@click.option("--timeout", default=30, type=click.IntRange(1,3600), help="Timeout (in second) to ping server")
@pass_cfg
def start(cfg, gradle, timeout):
    try:
        json_server = cfg.getServer()
        if ping(json_server):
            logging.info("Server already started")
            return 0
    except ConnectionRefusedError:
        pass

    start_jar(args, ["server"])

@server.command()
@pass_cfg
def stop(cfg):
    server = cfg.getServer()
    server.shutdown({})


@server.command()
@pass_cfg
def ping(cfg):
    r = cfg.getServer().ping({})
    if r == "pong":
        sys.exit(0)
    sys.exit(1)

# ---- Experiments


@main.group(help="Manage experiments")
def experiments(): pass

@experiments.command()
@click.option("--command", default="list", type=click.Choice(["list", "delete", "kill"]), help="Command to apply to obsolete tasks")
@pass_cfg
def process_obsolete(cfg, command):
    server = cfg.getServer()
    json.dump(server["experiments.process-obsolete"]({"command": command}), sys.stdout)

@experiments.command(help="Cleanup old experiments")
@click.option("--run", is_flag=True)
@click.option("--remove-resources", is_flag=True)
@pass_cfg
def clean(cfg, run, remove_resources):
    server = cfg.getServer()
    print(server.experiments["clean-experiments"]({"simulate": not run, "remove-resources": remove_resources}))



# ---- Tasks

@main.group()
def tasks(): pass

@tasks.command("rm", help="Remove tasks")
@pass_cfg
def rm(cfg):
    server = cfg.getServer()
    print("Updated job(s): %s" % server.updateJobs({
        "resources": args.resources,
        "recursive": args.recursive,
        "states": get_states(args.states)
    }))


@tasks.command(help="Update the status of tasks")
@pass_cfg
def update(cfg):
    server = cfg.getServer()
    print("Updated job(s): %s" % server.updateJobs({
        "resources": args.resources,
        "recursive": args.recursive,
        "states": get_states(args.states)
    }))


@tasks.command(help="List ressources")
@click.option("--color", is_flag=True, help="Whether to color the output")
@click.option("--recursive", is_flag=True, help="Recursive")
@click.option('--states', help="Restrict to states", type=click.Choice(STATES))
@pass_cfg
def ls(cfg, color, recursive, states):
    server = cfg.getServer()
    response = server.listJobs({"resources": [], "states": get_states(states), "recursive": recursive})
    for l in response:
        if color:
            state = l.get("state", "?").upper()
            if state == 'ERROR':
                print(cformat("#RED;%s" % l))
            elif state == 'DONE':
                print(cformat("#GREEN;%s" % l))
            elif state == 'RUNNING':
                print(cformat("#CYAN;%s" % l))
            elif state == 'ON_HOLD':
                print(cformat("#YELLOW;%s" % l))
            else:
                print(l)
        else:
            json.dump(l, sys.stdout)
            sys.stdout.write("\n")

def command_build_information(args):
    info = cfg.getServer().buildInformation({})
    json.dump(info, sys.stdout)
    sys.stdout.write("\n")

def command_list_methods(args):
    server = cfg.getServer()
    for method in server.system.listMethods():
        if not method.startswith("system"):
            print("# %s" % method)
            print(server.system.methodSignature(method))
            print(server.system.methodHelp(method))
            print


def command_information(args):
    server = cfg.getServer()
    json.dump(server.getResourceInformation({"id": args.resourceId[0]}), sys.stdout)
    sys.stdout.write("\n")

def Server(function):
    return lambda args : function(cfg.getServer(), args)

@Server
def command_set_token_limit(server, args):
    json.dump(server.setTokenLimit({"tokenId": args.tokenid, "limit": args.limit}), sys.stdout)

def command_invalidate(args):
    server = cfg.getServer()
    print(args)
    json_args = { "ids": args.resourceIds, "restart": args.restart, "recursive": args.recursive, "keep-done": args.keep_done}
    print(server.invalidate(json_args))


def command_experiments_invalidate(args):
    server = cfg.getServer()
    json_args = { "experimentId": args.experimentId, "restart": args.restart, "recursive": args.recursive,
                  "states": args.states.split(",")}
    count = server.experiments.invalidate(json_args)
    print("Restarted %d jobs " % count)


def command_kill(args):
    server = cfg.getServer()
    n = server.kill({"jobs": args.jobid})
    logging.info("Killed %d jobs" % n)

def command_experiments_kill(args):
    server = cfg.getServer()
    n = server.experiments.kill({"identifier": args.experimentid, "states": get_states(args.states)})
    logging.info("Killed %d jobs" % n)

def command_experiments_delete(args):
    server = cfg.getServer()
    count = server.experiments.delete({"identifier": args.experimentid})
    print("%d experiments deleted" % count)

def command_generate_files(args):
    server = cfg.getServer()
    server.generateFiles({"jobs": args.jobid})


def command_lock_cleanup(args):
    server = cfg.getServer()
    output = server["cleanup-locks"]({"simulate": not args.run})
    json.dump(output, sys.stdout)

def command_rm(args):
    server = cfg.getServer()
    if len(args.jobid) == 0:
        args.jobid = [""]

    states = get_states(args.states)
    if args.group is None:
        args.group = ""

    for jobid in args.jobid:
        n = server.remove({"group": args.group, "id": jobid, "states": states, "recursive": args.recursive, "regexp": args.regexp})
        print("Removed %d resources" % n)


def command_log_level(args):
    server = cfg.getServer()
    server.setLogLevel({"identifier": args.id[0], "level": args.level[0]})

def command_move_resources(args):
    server = cfg.getServer()
    server.changeResourcesPrefix({"old": args.old, "new": args.new})

def command_ssh_agent(args):
    server = cfg.getServer()
    print(json.dumps(server.sshAgentInformation({})))

# --- Utility functions


def get_states(states):
    if states is not None:
        states = args.states.split(",")
    else:
        states = []
    return states


# --- Run command


if __name__ == '__main__':
   main(obj=None)

